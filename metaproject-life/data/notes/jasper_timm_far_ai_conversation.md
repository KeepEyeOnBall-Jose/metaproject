Title: Conversation with Jasper Timm — Far.AI, refusals, evals, democracy agents
Created: 2025-10-01
Tags: jasper-timm, far-ai, ai-safety, evals, democracy-agents, general-technical

Category: General Technical (AI & SW Dev Tools)

Conversation summary

Had a conversation with Jasper Timm covering several AI safety and research topics, particularly around Far.AI (the NGO) and various technical approaches to AI alignment and evaluation.

Key topics discussed

- **Far.AI NGO**: Discussion about the organization and their work in AI safety research
- **Refusal oblation**: What happens when "you try to oblate all of the refusals" — implications for AI safety and alignment
- **Baby sleep schedule monitoring**: How to control/monitor sleep schedules — possibly related to data collection or behavioral monitoring systems
- **Evals (evaluations)**: AI model evaluation frameworks, benchmarks, and assessment methodologies
- **Democracy agents**: AI systems designed to facilitate or participate in democratic processes
- **Data labelling quality**: Discussion of BAD vs GOOD data labelling practices and their impact on model training
- **Jasper's capstone project**: His academic/research project (specifics to be documented)

Areas for follow-up research

- Far.AI's current research priorities and methodologies
- State of the art in AI refusal mechanisms and their limitations
- Evaluation frameworks for AI safety and alignment
- Democracy and governance applications of AI systems
- Best practices for data labelling in sensitive domains

Potential connections to current work

- How do these concepts apply to our AI tool usage (Copilot, etc.)?
- Relevance to data collection and processing in current projects
- Evaluation methodologies that could be applied to our development workflows

Done: saved as `data/notes/jasper_timm_far_ai_conversation.md`